{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b8f5b-0d7e-436a-9236-df04c340ea1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdaa679a-494c-47f3-aa96-fded5ecd7bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File batch status: completed\n",
      "File batch counts: FileCounts(cancelled=0, completed=9, failed=0, in_progress=0, total=9)\n",
      "No messages returned from the thread, attempt 1/5. Retrying...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 155\u001b[0m\n\u001b[0;32m    152\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Puedes ajustar el tiempo de espera si es necesario\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 155\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[4], line 139\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m thread \u001b[38;5;241m=\u001b[39m create_thread(client, assistant\u001b[38;5;241m.\u001b[39mid, message_file\u001b[38;5;241m.\u001b[39mid, content)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Esperar a que el hilo se ejecute completamente\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m messages \u001b[38;5;241m=\u001b[39m run_thread(client, thread\u001b[38;5;241m.\u001b[39mid, assistant\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m messages:\n\u001b[0;32m    142\u001b[0m     message_content \u001b[38;5;241m=\u001b[39m messages[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n",
      "Cell \u001b[1;32mIn[4], line 77\u001b[0m, in \u001b[0;36mrun_thread\u001b[1;34m(client, thread_id, assistant_id)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo messages returned from the thread, attempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/5. Retrying...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Espera 10 segundos antes de intentar nuevamente\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "def create_openai_client(api_key):\n",
    "    return OpenAI(api_key=api_key)\n",
    "\n",
    "def create_assistant(client, name, instructions, model=\"gpt-4o\"):\n",
    "    return client.beta.assistants.create(\n",
    "        name=name,\n",
    "        instructions=instructions,\n",
    "        model=model,\n",
    "        tools=[{\"type\": \"file_search\"}],\n",
    "    )\n",
    "\n",
    "def create_vector_store(client, name):\n",
    "    return client.beta.vector_stores.create(name=name)\n",
    "\n",
    "def extract_text_from_docx(file_paths):\n",
    "    extracted_texts = []\n",
    "    for path in file_paths:\n",
    "        doc = Document(path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "        extracted_texts.append(text)\n",
    "    return extracted_texts\n",
    "\n",
    "def save_texts_to_files(extracted_texts, output_dir, original_file_names):\n",
    "    temp_txt_paths = []\n",
    "    for i, text in enumerate(extracted_texts):\n",
    "        # Use the original DOCX file name for the TXT file\n",
    "        original_file_name = os.path.splitext(os.path.basename(original_file_names[i]))[0]\n",
    "        temp_txt_path = os.path.join(output_dir, f\"{original_file_name}.txt\")\n",
    "        with open(temp_txt_path, \"w\", encoding=\"utf-8\") as temp_file:\n",
    "            temp_file.write(text)\n",
    "        temp_txt_paths.append(temp_txt_path)\n",
    "    return temp_txt_paths\n",
    "\n",
    "def upload_files_to_vector_store(client, vector_store_id, temp_txt_paths):\n",
    "    file_streams = [open(path, \"rb\") for path in temp_txt_paths]\n",
    "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "        vector_store_id=vector_store_id, files=file_streams\n",
    "    )\n",
    "    return file_batch\n",
    "\n",
    "def create_message_file(client, file_path):\n",
    "    return client.files.create(\n",
    "        file=open(file_path, \"rb\"), purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "def create_thread(client, assistant_id, message_file_id, content):\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "                \"attachments\": [\n",
    "                    {\"file_id\": message_file_id, \"tools\": [{\"type\": \"file_search\"}]}\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return thread\n",
    "\n",
    "def run_thread(client, thread_id, assistant_id):\n",
    "    # Intentamos obtener mensajes hasta un máximo de 5 veces con un retraso entre cada intento\n",
    "    for attempt in range(5):\n",
    "        run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread_id, assistant_id=assistant_id\n",
    "        )\n",
    "        messages = list(client.beta.threads.messages.list(thread_id=thread_id, run_id=run.id))\n",
    "        \n",
    "        if messages:\n",
    "            return messages\n",
    "        else:\n",
    "            print(f\"No messages returned from the thread, attempt {attempt + 1}/5. Retrying...\")\n",
    "            time.sleep(10)  # Espera 10 segundos antes de intentar nuevamente\n",
    "\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    api_key = \"YOUR_API_KEY_HERE\"\n",
    "    client = create_openai_client(api_key)\n",
    "\n",
    "    assistant = create_assistant(\n",
    "        client,\n",
    "        name=\"Elaborador\",\n",
    "        instructions=\"\"\"Eres un experto en elaboración de preguntas didácticas para evaluaciones. \n",
    "        No proporcionas las fuentes ni haces citaciones. \n",
    "        No das un texto de introducción, ni de despedida. \n",
    "        Únicamente respondes con las preguntas solicitadas en el formato AIKEN, sin más ni menos.\"\"\"\n",
    "    )\n",
    "\n",
    "    vector_store = create_vector_store(client, name=\"Texto_adjunto\")\n",
    "\n",
    "    # Ruta del directorio donde están los archivos DOCX\n",
    "    input_dir = r\"C:\\Users\\HP\\Desktop\\CATO-CURSOS-2-2024\\GER-TI CATO1-2024\\Cursos\\SEMANA 2\\BUSINESS MODEL CANVAS\\texto_videos\"\n",
    "\n",
    "    # Crear carpeta \"preguntas\" si no existe\n",
    "    output_dir = os.path.join(input_dir, 'preguntas')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Lista de todos los archivos DOCX en el directorio\n",
    "    file_paths = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.docx')]\n",
    "\n",
    "    extracted_texts = extract_text_from_docx(file_paths)\n",
    "    temp_txt_paths = save_texts_to_files(extracted_texts, output_dir, file_paths)\n",
    "\n",
    "    file_batch = upload_files_to_vector_store(client, vector_store.id, temp_txt_paths)\n",
    "    print(\"File batch status:\", file_batch.status)\n",
    "    print(\"File batch counts:\", file_batch.file_counts)\n",
    "\n",
    "    assistant = client.beta.assistants.update(\n",
    "        assistant_id=assistant.id,\n",
    "        tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    "    )\n",
    "\n",
    "    for temp_txt_path in temp_txt_paths:\n",
    "        message_file = create_message_file(client, temp_txt_path)\n",
    "\n",
    "        content = \"\"\"Elabora VEINTE preguntas en formato AIKEN basadas en el texto proporcionado. \n",
    "        Las preguntas deben centrarse en el tema principal del texto. \n",
    "        No debes proporcionar citaciones ni incluir introducción o despedida. \n",
    "        Solo responde con las preguntas en el formato AIKEN.\n",
    "        \n",
    "        Ejemplo de preguntas:\n",
    "        \n",
    "        Según el texto de título: Business Storytelling Masterclass with Matteo Cassese, ¿qué es esencial para captar la atención del público en storytelling?\n",
    "        A) Utilizar terminología complicada\n",
    "        B) Hablar en un tono monótono\n",
    "        C) Empezar con una anécdota interesante\n",
    "        D) Presentar gráficos complejos\n",
    "        ANSWER: C\n",
    "        \"\"\"\n",
    "\n",
    "        thread = create_thread(client, assistant.id, message_file.id, content)\n",
    "        \n",
    "        # Esperar a que el hilo se ejecute completamente\n",
    "        messages = run_thread(client, thread.id, assistant.id)\n",
    "\n",
    "        if messages:\n",
    "            message_content = messages[0].content[0].text\n",
    "            # Guardar las preguntas en un archivo TXT en la carpeta \"preguntas\"\n",
    "            output_txt_path = os.path.join(output_dir, os.path.basename(temp_txt_path))\n",
    "            with open(output_txt_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "                output_file.write(message_content.value)\n",
    "            print(f\"Preguntas guardadas en: {output_txt_path}\")\n",
    "        else:\n",
    "            print(\"No messages returned from the thread after multiple attempts.\")\n",
    "\n",
    "        # Esperar un breve momento antes de pasar al siguiente archivo para asegurar que todo se haya completado\n",
    "        time.sleep(2)  # Puedes ajustar el tiempo de espera si es necesario\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86743225-39f4-4783-acff-94e5bea0a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "def create_openai_client(api_key):\n",
    "    return OpenAI(api_key=api_key)\n",
    "\n",
    "def create_assistant(client, name, instructions, model=\"gpt-4\"):\n",
    "    return client.beta.assistants.create(\n",
    "        name=name,\n",
    "        instructions=instructions,\n",
    "        model=model,\n",
    "        tools=[]\n",
    "    )\n",
    "\n",
    "def create_vector_store(client, name):\n",
    "    return client.beta.vector_stores.create(name=name)\n",
    "\n",
    "def extract_text_from_docx(file_paths):\n",
    "    extracted_texts = []\n",
    "    for path in file_paths:\n",
    "        doc = Document(path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "        extracted_texts.append(text)\n",
    "    return extracted_texts\n",
    "\n",
    "def save_texts_to_files(extracted_texts, output_dir, original_file_names):\n",
    "    temp_txt_paths = []\n",
    "    for i, text in enumerate(extracted_texts):\n",
    "        original_file_name = os.path.splitext(os.path.basename(original_file_names[i]))[0]\n",
    "        temp_txt_path = os.path.join(output_dir, f\"{original_file_name}.txt\")\n",
    "        with open(temp_txt_path, \"w\", encoding=\"utf-8\") as temp_file:\n",
    "            temp_file.write(text)\n",
    "        temp_txt_paths.append(temp_txt_path)\n",
    "    return temp_txt_paths\n",
    "\n",
    "def upload_files_to_vector_store(client, vector_store_id, temp_txt_paths):\n",
    "    file_streams = [open(path, \"rb\") for path in temp_txt_paths]\n",
    "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "        vector_store_id=vector_store_id, files=file_streams\n",
    "    )\n",
    "    return file_batch\n",
    "\n",
    "def create_message_file(client, file_path):\n",
    "    return client.files.create(\n",
    "        file=open(file_path, \"rb\"), purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "def create_thread(client, assistant_id, message_file_id, content):\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "                \"attachments\": [\n",
    "                    {\"file_id\": message_file_id}\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return thread\n",
    "\n",
    "def run_thread(client, thread_id, assistant_id):\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            run = client.beta.threads.runs.create_and_poll(\n",
    "                thread_id=thread_id, assistant_id=assistant_id\n",
    "            )\n",
    "            messages = list(client.beta.threads.messages.list(thread_id=thread_id, run_id=run.id))\n",
    "            if messages:\n",
    "                return messages\n",
    "            else:\n",
    "                print(f\"No messages returned from the thread, attempt {attempt + 1}/5. Retrying...\")\n",
    "                time.sleep(10)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during thread run: {str(e)}. Attempt {attempt + 1}/5. Retrying...\")\n",
    "            time.sleep(10)\n",
    "\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    api_key = \"YOUR_API_KEY_HERE\"\n",
    "    client = create_openai_client(api_key)\n",
    "\n",
    "    assistant = create_assistant(\n",
    "        client,\n",
    "        name=\"Elaborador\",\n",
    "        instructions=\"\"\"Eres un experto en elaboración de preguntas didácticas para evaluaciones. \n",
    "        No proporcionas las fuentes ni haces citaciones. \n",
    "        No das un texto de introducción, ni de despedida. \n",
    "        Únicamente respondes con las preguntas solicitadas en el formato AIKEN, sin más ni menos.\"\"\"\n",
    "    )\n",
    "\n",
    "    vector_store = create_vector_store(client, name=\"Texto_adjunto\")\n",
    "\n",
    "    input_dir = r\"C:\\Users\\HP\\Desktop\\CATO-CURSOS-2-2024\\GER-TI CATO1-2024\\Cursos\\SEMANA 2\\BUSINESS MODEL CANVAS\\texto_videos\"\n",
    "    output_dir = os.path.join(input_dir, 'preguntas')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    file_paths = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.docx')]\n",
    "\n",
    "    extracted_texts = extract_text_from_docx(file_paths)\n",
    "    temp_txt_paths = save_texts_to_files(extracted_texts, output_dir, file_paths)\n",
    "\n",
    "    file_batch = upload_files_to_vector_store(client, vector_store.id, temp_txt_paths)\n",
    "    print(\"File batch status:\", file_batch.status)\n",
    "    print(\"File batch counts:\", file_batch.file_counts)\n",
    "\n",
    "    assistant = client.beta.assistants.update(\n",
    "        assistant_id=assistant.id,\n",
    "        tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    "    )\n",
    "\n",
    "    for temp_txt_path in temp_txt_paths:\n",
    "        message_file = create_message_file(client, temp_txt_path)\n",
    "\n",
    "        content = \"\"\"Elabora VEINTE preguntas en formato AIKEN basadas en el texto proporcionado. \n",
    "        Las preguntas deben centrarse en el tema principal del texto. \n",
    "        No debes proporcionar citaciones ni incluir introducción o despedida. \n",
    "        Solo responde con las preguntas en el formato AIKEN.\"\"\"\n",
    "\n",
    "        thread = create_thread(client, assistant.id, message_file.id, content)\n",
    "\n",
    "        messages = run_thread(client, thread.id, assistant.id)\n",
    "\n",
    "        if messages:\n",
    "            message_content = messages[0].content\n",
    "            output_txt_path = os.path.join(output_dir, os.path.basename(temp_txt_path))\n",
    "            with open(output_txt_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "                output_file.write(message_content)\n",
    "            print(f\"Preguntas guardadas en: {output_txt_path}\")\n",
    "        else:\n",
    "            print(\"No messages returned from the thread after multiple attempts.\")\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6d8b4-8e89-4d1d-949b-90f0a57296a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
